"""
FastAPI pour tester les scrapers Playwright en local.
Lance avec: uvicorn api_scraper:app --reload
AccÃ¨de Ã : http://127.0.0.1:8000/docs (interface Swagger)
"""

from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.responses import JSONResponse
from datetime import datetime
import sys
import os

# Ajouter le dossier courant au path pour les imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

app = FastAPI(
    title="ğŸ•·ï¸ Scraper API - Missing Codes",
    description="""
    API pour lancer les scrapers de codes promo.
    
    Les rÃ©sultats sont Ã©crits directement dans Google Sheets (Missing_Code).
    
    ## Scrapers disponibles:
    - ğŸ‡¦ğŸ‡º AU: Lifehacker, Cuponation
    - ğŸ‡ºğŸ‡¸ US: RetailMeNot, SimplyCodes
    - ğŸ‡¬ğŸ‡§ UK: HotUKDeals, VoucherCodes
    - ğŸ‡©ğŸ‡ª DE: MyDealz, Sparwelt
    - ğŸ‡«ğŸ‡· FR: iGraal, Ma-Reduc
    - ğŸ‡ªğŸ‡¸ ES: Chollometro, Cuponation
    - ğŸ‡®ğŸ‡¹ IT: Codice-Sconto, Cuponation
    """,
    version="1.0.0"
)

# Variable globale pour suivre le statut
scraper_status = {
    "running": False,
    "last_run": None,
    "last_source": None,
    "last_result": None
}


@app.get("/", tags=["Info"])
def root():
    """Page d'accueil - redirige vers /docs pour l'interface Swagger."""
    return {
        "message": "ğŸ•·ï¸ Scraper API - Missing Codes",
        "docs": "AccÃ©dez Ã  /docs pour l'interface Swagger",
        "status": scraper_status
    }


@app.get("/status", tags=["Info"])
def get_status():
    """VÃ©rifie le statut du scraper."""
    return scraper_status


# ===================================================================
# AUSTRALIE
# ===================================================================

@app.post("/scrape/au/lifehacker", tags=["ğŸ‡¦ğŸ‡º Australie"])
def scrape_lifehacker_au():
    """
    ğŸ‡¦ğŸ‡º Lance le scraper Lifehacker Australie.
    
    Les codes sont Ã©crits directement dans Google Sheets.
    """
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Lifehacker AU"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        # Import et exÃ©cution du scraper
        from AU.scrap_lifehacker_AU import main as scrape_lifehacker
        scrape_lifehacker()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Lifehacker AU terminÃ©", "source": "Lifehacker AU"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/au/cuponation", tags=["ğŸ‡¦ğŸ‡º Australie"])
def scrape_cuponation_au():
    """ğŸ‡¦ğŸ‡º Lance le scraper Cuponation Australie."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Cuponation AU"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from AU.scrap_cuponation_AU import main as scrape_cuponation
        scrape_cuponation()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Cuponation AU terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# USA
# ===================================================================

@app.post("/scrape/us/retailmenot", tags=["ğŸ‡ºğŸ‡¸ USA"])
def scrape_retailmenot_us():
    """ğŸ‡ºğŸ‡¸ Lance le scraper RetailMeNot USA."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "RetailMeNot US"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from US.scrap_retailmenot_US import main as scrape_retailmenot
        scrape_retailmenot()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping RetailMeNot US terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/us/simplycodes", tags=["ğŸ‡ºğŸ‡¸ USA"])
def scrape_simplycodes_us():
    """ğŸ‡ºğŸ‡¸ Lance le scraper SimplyCodes USA."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "SimplyCodes US"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from US.scrap_simplycodes_US import main as scrape_simplycodes
        scrape_simplycodes()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping SimplyCodes US terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# UK
# ===================================================================

@app.post("/scrape/uk/hotukdeals", tags=["ğŸ‡¬ğŸ‡§ UK"])
def scrape_hotukdeals_uk():
    """ğŸ‡¬ğŸ‡§ Lance le scraper HotUKDeals UK."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "HotUKDeals UK"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from UK.scrap_hotukdeals_UK import main as scrape_hotukdeals
        scrape_hotukdeals()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping HotUKDeals UK terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/uk/vouchercodes", tags=["ğŸ‡¬ğŸ‡§ UK"])
def scrape_vouchercodes_uk():
    """ğŸ‡¬ğŸ‡§ Lance le scraper VoucherCodes UK."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "VoucherCodes UK"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from UK.scrap_vouchercodes_UK import main as scrape_vouchercodes
        scrape_vouchercodes()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping VoucherCodes UK terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# ALLEMAGNE
# ===================================================================

@app.post("/scrape/de/mydealz", tags=["ğŸ‡©ğŸ‡ª Allemagne"])
def scrape_mydealz_de():
    """ğŸ‡©ğŸ‡ª Lance le scraper MyDealz Allemagne."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "MyDealz DE"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from DE.scrap_mydealz_DE import main as scrape_mydealz
        scrape_mydealz()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping MyDealz DE terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/de/sparwelt", tags=["ğŸ‡©ğŸ‡ª Allemagne"])
def scrape_sparwelt_de():
    """ğŸ‡©ğŸ‡ª Lance le scraper Sparwelt Allemagne."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Sparwelt DE"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from DE.scrap_sparwelt_DE import main as scrape_sparwelt
        scrape_sparwelt()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Sparwelt DE terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# FRANCE
# ===================================================================

@app.post("/scrape/fr/igraal", tags=["ğŸ‡«ğŸ‡· France"])
def scrape_igraal_fr():
    """ğŸ‡«ğŸ‡· Lance le scraper iGraal France."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "iGraal FR"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from FR.scrap_igraal_FR import main as scrape_igraal
        scrape_igraal()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping iGraal FR terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/fr/mareduc", tags=["ğŸ‡«ğŸ‡· France"])
def scrape_mareduc_fr():
    """ğŸ‡«ğŸ‡· Lance le scraper Ma-Reduc France."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Ma-Reduc FR"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from FR.scrap_mareduc_FR import main as scrape_mareduc
        scrape_mareduc()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Ma-Reduc FR terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# ESPAGNE
# ===================================================================

@app.post("/scrape/es/chollometro", tags=["ğŸ‡ªğŸ‡¸ Espagne"])
def scrape_chollometro_es():
    """ğŸ‡ªğŸ‡¸ Lance le scraper Chollometro Espagne."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Chollometro ES"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from ES.scrap_chollometro_ES import main as scrape_chollometro
        scrape_chollometro()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Chollometro ES terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/es/cuponation", tags=["ğŸ‡ªğŸ‡¸ Espagne"])
def scrape_cuponation_es():
    """ğŸ‡ªğŸ‡¸ Lance le scraper Cuponation Espagne."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Cuponation ES"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from ES.scrap_cuponation_ES import main as scrape_cuponation
        scrape_cuponation()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Cuponation ES terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# ITALIE
# ===================================================================

@app.post("/scrape/it/codicescontonet", tags=["ğŸ‡®ğŸ‡¹ Italie"])
def scrape_codicescontonet_it():
    """ğŸ‡®ğŸ‡¹ Lance le scraper Codice-Sconto.net Italie."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Codicescontonet IT"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from IT.scrap_codicescontonet_IT import main as scrape_codicescontonet
        scrape_codicescontonet()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Codicescontonet IT terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/it/cuponation", tags=["ğŸ‡®ğŸ‡¹ Italie"])
def scrape_cuponation_it():
    """ğŸ‡®ğŸ‡¹ Lance le scraper Cuponation Italie."""
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    try:
        scraper_status["running"] = True
        scraper_status["last_source"] = "Cuponation IT"
        scraper_status["last_run"] = datetime.now().isoformat()
        
        from IT.scrap_cuponation_IT import main as scrape_cuponation
        scrape_cuponation()
        
        scraper_status["last_result"] = "âœ… SuccÃ¨s"
        return {"status": "success", "message": "Scraping Cuponation IT terminÃ©"}
    
    except Exception as e:
        scraper_status["last_result"] = f"âŒ Erreur: {str(e)[:100]}"
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# GROUPES DE SCRAPERS (pour Cloud Scheduler)
# ===================================================================

@app.post("/scrape/group1", tags=["ğŸ“¦ Groupes"])
def scrape_group1():
    """
    ğŸ“¦ Groupe 1: AU + IT (4 scrapers)
    
    - ğŸ‡¦ğŸ‡º Lifehacker AU
    - ğŸ‡¦ğŸ‡º Cuponation AU
    - ğŸ‡®ğŸ‡¹ Codicescontonet IT
    - ğŸ‡®ğŸ‡¹ Cuponation IT
    
    â±ï¸ DurÃ©e estimÃ©e: 30-45 minutes
    """
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    results = []
    errors = []
    
    scrapers = [
        ("AU/Lifehacker", "AU.scrap_lifehacker_AU", "main"),
        ("AU/Cuponation", "AU.scrap_cuponation_AU", "main"),
        ("IT/Codicescontonet", "IT.scrap_codicescontonet_IT", "main"),
        ("IT/Cuponation", "IT.scrap_cuponation_IT", "main"),
    ]
    
    scraper_status["running"] = True
    scraper_status["last_source"] = "GROUP1 (AU+IT)"
    scraper_status["last_run"] = datetime.now().isoformat()
    
    try:
        for name, module, func in scrapers:
            try:
                print(f"\n{'='*60}")
                print(f"ğŸš€ [GROUP1] Lancement de {name}...")
                print(f"{'='*60}")
                
                mod = __import__(module, fromlist=[func])
                getattr(mod, func)()
                results.append(f"âœ… {name}")
            except Exception as e:
                errors.append(f"âŒ {name}: {str(e)[:50]}")
        
        scraper_status["last_result"] = f"GROUP1: âœ… {len(results)} succÃ¨s, {len(errors)} erreurs"
        
        return {
            "status": "completed",
            "group": "GROUP1 (AU+IT)",
            "success": results,
            "errors": errors,
            "total_success": len(results),
            "total_errors": len(errors)
        }
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/group2", tags=["ğŸ“¦ Groupes"])
def scrape_group2():
    """
    ğŸ“¦ Groupe 2: UK + US (4 scrapers)
    
    - ğŸ‡¬ğŸ‡§ HotUKDeals UK
    - ğŸ‡¬ğŸ‡§ VoucherCodes UK
    - ğŸ‡ºğŸ‡¸ RetailMeNot US
    - ğŸ‡ºğŸ‡¸ SimplyCodes US
    
    â±ï¸ DurÃ©e estimÃ©e: 1h - 1h30
    """
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    results = []
    errors = []
    
    scrapers = [
        ("UK/HotUKDeals", "UK.scrap_hotukdeals_UK", "main"),
        ("UK/VoucherCodes", "UK.scrap_vouchercodes_UK", "main"),
        ("US/RetailMeNot", "US.scrap_retailmenot_US", "main"),
        ("US/SimplyCodes", "US.scrap_simplycodes_US", "main"),
    ]
    
    scraper_status["running"] = True
    scraper_status["last_source"] = "GROUP2 (UK+US)"
    scraper_status["last_run"] = datetime.now().isoformat()
    
    try:
        for name, module, func in scrapers:
            try:
                print(f"\n{'='*60}")
                print(f"ğŸš€ [GROUP2] Lancement de {name}...")
                print(f"{'='*60}")
                
                mod = __import__(module, fromlist=[func])
                getattr(mod, func)()
                results.append(f"âœ… {name}")
            except Exception as e:
                errors.append(f"âŒ {name}: {str(e)[:50]}")
        
        scraper_status["last_result"] = f"GROUP2: âœ… {len(results)} succÃ¨s, {len(errors)} erreurs"
        
        return {
            "status": "completed",
            "group": "GROUP2 (UK+US)",
            "success": results,
            "errors": errors,
            "total_success": len(results),
            "total_errors": len(errors)
        }
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/group3", tags=["ğŸ“¦ Groupes"])
def scrape_group3():
    """
    ğŸ“¦ Groupe 3: DE + FR (4 scrapers)
    
    - ğŸ‡©ğŸ‡ª MyDealz DE
    - ğŸ‡©ğŸ‡ª Sparwelt DE
    - ğŸ‡«ğŸ‡· iGraal FR
    - ğŸ‡«ğŸ‡· Ma-Reduc FR
    
    â±ï¸ DurÃ©e estimÃ©e: 1h - 1h30
    """
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    results = []
    errors = []
    
    scrapers = [
        ("DE/MyDealz", "DE.scrap_mydealz_DE", "main"),
        ("DE/Sparwelt", "DE.scrap_sparwelt_DE", "main"),
        ("FR/iGraal", "FR.scrap_igraal_FR", "main"),
        ("FR/Ma-Reduc", "FR.scrap_mareduc_FR", "main"),
    ]
    
    scraper_status["running"] = True
    scraper_status["last_source"] = "GROUP3 (DE+FR)"
    scraper_status["last_run"] = datetime.now().isoformat()
    
    try:
        for name, module, func in scrapers:
            try:
                print(f"\n{'='*60}")
                print(f"ğŸš€ [GROUP3] Lancement de {name}...")
                print(f"{'='*60}")
                
                mod = __import__(module, fromlist=[func])
                getattr(mod, func)()
                results.append(f"âœ… {name}")
            except Exception as e:
                errors.append(f"âŒ {name}: {str(e)[:50]}")
        
        scraper_status["last_result"] = f"GROUP3: âœ… {len(results)} succÃ¨s, {len(errors)} erreurs"
        
        return {
            "status": "completed",
            "group": "GROUP3 (DE+FR)",
            "success": results,
            "errors": errors,
            "total_success": len(results),
            "total_errors": len(errors)
        }
    
    finally:
        scraper_status["running"] = False


@app.post("/scrape/group4", tags=["ğŸ“¦ Groupes"])
def scrape_group4():
    """
    ğŸ“¦ Groupe 4: ES (2 scrapers)
    
    - ğŸ‡ªğŸ‡¸ Chollometro ES
    - ğŸ‡ªğŸ‡¸ Cuponation ES
    
    â±ï¸ DurÃ©e estimÃ©e: 30-45 minutes
    """
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    results = []
    errors = []
    
    scrapers = [
        ("ES/Chollometro", "ES.scrap_chollometro_ES", "main"),
        ("ES/Cuponation", "ES.scrap_cuponation_ES", "main"),
    ]
    
    scraper_status["running"] = True
    scraper_status["last_source"] = "GROUP4 (ES)"
    scraper_status["last_run"] = datetime.now().isoformat()
    
    try:
        for name, module, func in scrapers:
            try:
                print(f"\n{'='*60}")
                print(f"ğŸš€ [GROUP4] Lancement de {name}...")
                print(f"{'='*60}")
                
                mod = __import__(module, fromlist=[func])
                getattr(mod, func)()
                results.append(f"âœ… {name}")
            except Exception as e:
                errors.append(f"âŒ {name}: {str(e)[:50]}")
        
        scraper_status["last_result"] = f"GROUP4: âœ… {len(results)} succÃ¨s, {len(errors)} erreurs"
        
        return {
            "status": "completed",
            "group": "GROUP4 (ES)",
            "success": results,
            "errors": errors,
            "total_success": len(results),
            "total_errors": len(errors)
        }
    
    finally:
        scraper_status["running"] = False


# ===================================================================
# LANCER TOUS LES SCRAPERS
# ===================================================================

@app.post("/scrape/all", tags=["ğŸŒ Tous"])
def scrape_all():
    """
    ğŸŒ Lance TOUS les scrapers (14 au total).
    
    âš ï¸ Attention: Cela peut prendre plusieurs minutes!
    """
    global scraper_status
    
    if scraper_status["running"]:
        raise HTTPException(status_code=409, detail="Un scraper est dÃ©jÃ  en cours d'exÃ©cution")
    
    results = []
    errors = []
    
    scrapers = [
        ("AU/Lifehacker", "AU.scrap_lifehacker_AU", "main"),
        ("AU/Cuponation", "AU.scrap_cuponation_AU", "main"),
        ("US/RetailMeNot", "US.scrap_retailmenot_US", "main"),
        ("US/SimplyCodes", "US.scrap_simplycodes_US", "main"),
        ("UK/HotUKDeals", "UK.scrap_hotukdeals_UK", "main"),
        ("UK/VoucherCodes", "UK.scrap_vouchercodes_UK", "main"),
        ("DE/MyDealz", "DE.scrap_mydealz_DE", "main"),
        ("DE/Sparwelt", "DE.scrap_sparwelt_DE", "main"),
        ("FR/iGraal", "FR.scrap_igraal_FR", "main"),
        ("FR/Ma-Reduc", "FR.scrap_mareduc_FR", "main"),
        ("ES/Chollometro", "ES.scrap_chollometro_ES", "main"),
        ("ES/Cuponation", "ES.scrap_cuponation_ES", "main"),
        ("IT/Codicescontonet", "IT.scrap_codicescontonet_IT", "main"),
        ("IT/Cuponation", "IT.scrap_cuponation_IT", "main"),
    ]
    
    scraper_status["running"] = True
    scraper_status["last_source"] = "ALL"
    scraper_status["last_run"] = datetime.now().isoformat()
    
    try:
        for name, module, func in scrapers:
            try:
                print(f"\n{'='*60}")
                print(f"ğŸš€ Lancement de {name}...")
                print(f"{'='*60}")
                
                mod = __import__(module, fromlist=[func])
                getattr(mod, func)()
                results.append(f"âœ… {name}")
            except Exception as e:
                errors.append(f"âŒ {name}: {str(e)[:50]}")
        
        scraper_status["last_result"] = f"âœ… {len(results)} succÃ¨s, {len(errors)} erreurs"
        
        return {
            "status": "completed",
            "success": results,
            "errors": errors,
            "total_success": len(results),
            "total_errors": len(errors)
        }
    
    finally:
        scraper_status["running"] = False


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
