"""
Script pour analyser et classifier les codes promo avec un LLM.
- Lit les donn√©es depuis Google Sheets (Missing_Code)
- Classifie chaque code en 3 cat√©gories de fiabilit√©
- R√©√©crit les titres selon les guidelines
- Output en JSON
"""

import gspread
from google.oauth2.service_account import Credentials
import os
import json
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

# Charger les variables d'environnement depuis .env
load_dotenv()

# ===================================================================
# CONFIGURATION
# ===================================================================

# Format du nom du spreadsheet avec la date du jour
SPREADSHEET_NAME_FORMAT = "Missing_Deals_Coupons_{date}"  # {date} sera remplac√© par MM_DD_YYYY

# Liste des sheets pays √† traiter (US exclu)
COUNTRY_SHEETS = ["UK", "AU", "DE", "ES", "FR", "IT"]

# Chemin des credentials Google Sheets
_local_path = os.path.join(os.path.dirname(__file__), "..", "credentials", "service_account.json")
_cloud_path = "/app/credentials/service_account.json"
CREDENTIALS_PATH = _cloud_path if os.path.exists(_cloud_path) else _local_path

SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]

# OpenAI API Key (from environment variable)
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# ===================================================================
# TITLE REWRITING RULES
# ===================================================================

REWRITE_RULES = """
## TITLE REWRITING RULES:

**üö´ NEVER DO:**
- Never include the merchant/brand name in the rewritten title
- Never just rephrase with similar words - create something genuinely different
- Never exceed 100 characters

**‚úÖ ALWAYS DO:**
- Front-load the value: Put the discount/offer at the beginning
- Be specific: Include exact amounts, percentages, or product categories
- Use Title Case: Capitalize major words
- Make it scannable: Value should be instantly clear in 2-3 seconds

**REWRITING APPROACH** - Choose the best fit:
1. Action-Oriented: Create urgency with powerful verbs
2. Benefit-Driven: Focus on what the customer gets
3. Value-First: Lead with the concrete offer

**EXAMPLES:**
- ‚ùå "Temu - Shop Now and Save Big" ‚Üí ‚úÖ "90% Off Top Categories Today"
- ‚ùå "Check Out Our Latest Deals" ‚Üí ‚úÖ "20% Off New Arrivals This Week"
- ‚ùå "Home Depot Savings Event" ‚Üí ‚úÖ "Save $100 on Major Appliances"

If the original title already contains good value info, extract and front-load it.
If the title is vague, infer the likely offer from the code pattern and create a compelling title.
"""


# ===================================================================
# FUNCTIONS
# ===================================================================

def get_gspread_client():
    """Cr√©e un client gspread authentifi√©."""
    creds = Credentials.from_service_account_file(CREDENTIALS_PATH, scopes=SCOPES)
    return gspread.authorize(creds)


def find_todays_spreadsheet(client):
    """
    Trouve le spreadsheet du jour dans Google Drive.
    
    Args:
        client: Client gspread authentifi√©
    
    Returns:
        Objet Spreadsheet ou None si non trouv√©
    """
    today = datetime.now().strftime("%m_%d_%Y")  # Format: MM_DD_YYYY
    spreadsheet_name = SPREADSHEET_NAME_FORMAT.format(date=today)
    
    print(f"üîç Recherche du spreadsheet: {spreadsheet_name}")
    
    try:
        spreadsheet = client.open(spreadsheet_name)
        print(f"   ‚úÖ Spreadsheet trouv√©: {spreadsheet.title}")
        return spreadsheet
    except gspread.SpreadsheetNotFound:
        print(f"   ‚ùå Spreadsheet non trouv√©: {spreadsheet_name}")
        return None


def ensure_llm_columns(worksheet):
    """
    Ajoute les colonnes Rewritten_Title et Spam_Code apr√®s la colonne Title si elles n'existent pas.
    
    Args:
        worksheet: Objet worksheet gspread
    
    Returns:
        tuple: (title_col_index, rewritten_title_col_index, spam_code_col_index)
    """
    header = worksheet.row_values(1)
    
    # Trouver l'index de la colonne Title
    try:
        title_idx = header.index("Title") + 1  # +1 car gspread utilise 1-based indexing
    except ValueError:
        raise ValueError("Colonne 'Title' non trouv√©e dans le header")
    
    # V√©rifier si les colonnes existent d√©j√†
    rewritten_title_col = title_idx + 1
    spam_code_col = title_idx + 2
    
    cols_to_add = []
    
    # V√©rifier Rewritten_Title
    if len(header) < rewritten_title_col or header[rewritten_title_col - 1] != "Rewritten_Title":
        cols_to_add.append("Rewritten_Title")
    
    # Re-lire le header apr√®s potentielle insertion
    if cols_to_add:
        print(f"   üìù Ajout des colonnes apr√®s 'Title' (col {title_idx})")
        worksheet.insert_cols(values=[[col] for col in cols_to_add], col=rewritten_title_col)
        header = worksheet.row_values(1)  # Re-lire le header
        print(f"   ‚úÖ Colonne ajout√©e: Rewritten_Title (col {rewritten_title_col})")
    
    # V√©rifier Spam_Code (apr√®s Rewritten_Title)
    header = worksheet.row_values(1)
    try:
        rewritten_title_col = header.index("Rewritten_Title") + 1
        spam_code_col = rewritten_title_col + 1
    except ValueError:
        pass
    
    if len(header) < spam_code_col or header[spam_code_col - 1] != "Spam_Code":
        print(f"   üìù Ajout de la colonne Spam_Code (col {spam_code_col})")
        worksheet.insert_cols(values=[["Spam_Code"]], col=spam_code_col)
        print(f"   ‚úÖ Colonne ajout√©e: Spam_Code (col {spam_code_col})")
    else:
        print(f"   ‚úÖ Colonnes LLM d√©j√† pr√©sentes")
    
    return title_idx, rewritten_title_col, spam_code_col


def get_missing_codes(worksheet, batch_size: int = 100):
    """
    R√©cup√®re les codes depuis une worksheet sp√©cifique.
    
    Args:
        worksheet: Objet worksheet gspread
        batch_size: Nombre de lignes √† r√©cup√©rer par batch (d√©faut: 100)
    
    Returns:
        Liste de dictionnaires avec les donn√©es + row_index + col_indices
    """
    print(f"üì• R√©cup√©ration des donn√©es de la sheet '{worksheet.title}'...")
    
    # S'assurer que les colonnes LLM existent
    title_idx, rewritten_title_col, spam_code_col = ensure_llm_columns(worksheet)
    
    all_records = worksheet.get_all_records()
    
    # Filtrer uniquement ceux qui n'ont PAS encore √©t√© trait√©s (pas de Rewritten_Title)
    unprocessed = [r for r in all_records if not r.get("Rewritten_Title")]
    print(f"   üìù {len(unprocessed)} codes non trait√©s sur {len(all_records)} au total")
    
    # Prendre seulement le batch_size demand√©
    batch = unprocessed[:batch_size]
    
    # Ajouter l'index de ligne pour pouvoir updater plus tard
    # (row_index = position dans la sheet, +2 car header + index 1-based)
    batch_with_index = []
    for record in batch:
        # Trouver l'index r√©el dans all_records
        try:
            original_index = all_records.index(record)
            record["_row_index"] = original_index + 2  # +2 pour header et 1-based
            record["_rewritten_col"] = rewritten_title_col
            record["_spam_col"] = spam_code_col
            batch_with_index.append(record)
        except ValueError:
            continue
    
    print(f"üìä Batch de {len(batch_with_index)} codes √† traiter")
    return batch_with_index


def get_missing_codes_OLD(batch_size: int = 100, filter_today: bool = True):
    """
    ANCIENNE VERSION - R√©cup√®re les codes depuis la sheet Missing_Code.
    Conserv√©e pour r√©f√©rence uniquement.
    """
    print("‚ö†Ô∏è Utilisation de l'ancienne fonction - deprecated")
    return [], None


def analyze_batch_with_llm(records: list, client: OpenAI, country: str) -> list:
    """
    R√©√©crit les titres d'un batch en une seule requ√™te LLM.
    
    Args:
        records: Liste de dictionnaires avec les donn√©es des codes
        client: Client OpenAI
        country: Code pays (UK, US, AU, DE, ES, FR, IT) pour la langue
    
    Returns:
        Liste de dictionnaires avec id et rewritten_title pour chaque code
    
    Raises:
        Exception: Si l'API √©choue (pas de fallback)
    """
    # Mapper les pays aux langues
    COUNTRY_LANGUAGES = {
        "UK": "English",
        "US": "English", 
        "AU": "English",
        "DE": "German",
        "ES": "Spanish",
        "FR": "French",
        "IT": "Italian"
    }
    language = COUNTRY_LANGUAGES.get(country, "English")
    
    # Construire le prompt avec uniquement les donn√©es essentielles
    codes_data = []
    for idx, record in enumerate(records, 1):
        codes_data.append({
            "id": idx,
            "code": record.get("Code", ""),
            "title": record.get("Title", "")
        })
    
    batch_prompt = f"""Rewrite {len(codes_data)} promo code titles in {language} following these rules:

{REWRITE_RULES}

IMPORTANT: All rewritten titles MUST be in {language}.

Also, for each code, determine if it's a SPAM/FAKE code:
- spam_code = true if: affiliate codes (HONEY, RAKUTEN, etc.), random strings, auto-generated codes, competitor codes
- spam_code = false if: looks like a legitimate promo code

TITLES TO REWRITE:
{json.dumps(codes_data)}

RESPOND WITH JSON ARRAY ONLY:
[{{"id":1,"rewritten_title":"...in {language}...","spam_code":false}},...]
"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": f"Rewrite titles in {language} and detect spam codes. JSON array only."},
            {"role": "user", "content": batch_prompt}
        ],
        temperature=0.3,
        max_tokens=min(len(records) * 50, 16000)  # ~50 tokens par titre, max 16000
    )
    
    result_text = response.choices[0].message.content.strip()
    
    # Nettoyer si le LLM ajoute des backticks markdown
    if result_text.startswith("```"):
        result_text = result_text.split("```")[1]
        if result_text.startswith("json"):
            result_text = result_text[4:]
    result_text = result_text.strip()
    
    results = json.loads(result_text)
    
    # V√©rifier que le nombre de r√©sultats correspond
    if len(results) != len(records):
        raise ValueError(f"Expected {len(records)} results, got {len(results)}")
    
    return results


def analyze_all_codes(records: list, country: str) -> list:
    """
    R√©√©crit les titres du batch en UNE SEULE requ√™te LLM.
    
    Args:
        records: Liste des codes √† traiter
        country: Code pays pour la langue (UK, DE, ES, FR, IT, etc.)
    
    Returns:
        Liste de r√©sultats avec les donn√©es originales + titre r√©√©crit
    """
    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY environment variable not set!")
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    print(f"\nü§ñ R√©√©criture de {len(records)} titres avec GPT-4o-mini...")
    
    # Traiter tout le batch en une seule fois
    analyses = analyze_batch_with_llm(records, client, country)
    
    # Associer les r√©sultats aux records originaux
    results = []
    for idx, record in enumerate(records):
        # Trouver l'analyse correspondante par ID
        analysis = next((a for a in analyses if a.get("id") == idx + 1), None)
        
        if analysis:
            result = {
                "original_data": record,
                "analysis": analysis
            }
            results.append(result)
            print(f"   [{idx+1}/{len(records)}] {record.get('Title', '')[:40]} ‚Üí {analysis['rewritten_title'][:40]}")
        else:
            print(f"   [{idx+1}/{len(records)}] ‚ùå No result for code {idx+1}")
    
    print(f"   ‚úÖ Batch de {len(results)} titres r√©√©crits")
    return results


def update_sheet_with_results(worksheet, results: list):
    """
    Met √† jour le Google Sheet avec les titres r√©√©crits.
    Met √† jour les colonnes Rewritten_Title et Spam_Code.
    
    Args:
        worksheet: Objet worksheet gspread
        results: Liste des r√©sultats
    """
    print("\nüìù Mise √† jour du Google Sheet...")
    
    # Batch update pour √™tre plus rapide
    updates = []
    
    for r in results:
        row_index = r["original_data"].get("_row_index")
        rewritten_col = r["original_data"].get("_rewritten_col")
        spam_col = r["original_data"].get("_spam_col")
        
        if not row_index or not rewritten_col:
            continue
        
        analysis = r["analysis"]
        
        # Convertir les indices de colonnes en lettres (A, B, C, etc.)
        from gspread.utils import rowcol_to_a1
        
        # Rewritten_Title
        rewritten_cell = rowcol_to_a1(row_index, rewritten_col)
        updates.append({
            "range": rewritten_cell,
            "values": [[analysis["rewritten_title"]]]
        })
        
        # Spam_Code
        if spam_col:
            spam_cell = rowcol_to_a1(row_index, spam_col)
            spam_value = "True" if analysis.get("spam_code", False) else "False"
            updates.append({
                "range": spam_cell,
                "values": [[spam_value]]
            })
    
    # Faire le batch update
    if updates:
        worksheet.batch_update(updates)
        print(f"   ‚úÖ {len(results)} lignes mises √† jour dans la sheet '{worksheet.title}'")
    else:
        print("   ‚ö†Ô∏è Aucune ligne √† mettre √† jour")


def save_results_json(results: list, output_path: str = None):
    """
    Sauvegarde les r√©sultats en JSON.
    
    Args:
        results: Liste des r√©sultats d'analyse
        output_path: Chemin du fichier JSON (optionnel)
    
    Returns:
        Chemin du fichier cr√©√©
    """
    if not output_path:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(
            os.path.dirname(__file__),
            "Output",
            f"code_analysis_{timestamp}.json"
        )
    
    # Cr√©er le dossier si n√©cessaire
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # Formater les r√©sultats pour le JSON final
    formatted_results = []
    for r in results:
        formatted_results.append({
            "merchant_slug": r["original_data"].get("Merchant_slug"),
            "country": r["original_data"].get("Country"),
            "code": r["original_data"].get("Code"),
            "original_title": r["original_data"].get("Title"),
            "rewritten_title": r["analysis"]["rewritten_title"]
        })
    
    output_data = {
        "generated_at": datetime.now().isoformat(),
        "total_codes": len(formatted_results),
        "results": formatted_results
    }
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ R√©sultats sauvegard√©s: {output_path}")
    return output_path


def print_summary(results: list):
    """Affiche un r√©sum√© des r√©sultats."""
    total = len(results)
    
    print(f"\n{'='*60}")
    print("üìä R√âSUM√â")
    print(f"{'='*60}")
    print(f"Total titres r√©√©crits: {total}")
    print(f"{'='*60}")


def main(batch_size: int = 100, countries: list = None):
    """
    Fonction principale - traite les codes par pays (sheet par sheet).
    
    Args:
        batch_size: Nombre de codes par batch (d√©faut: 100)
        countries: Liste des pays √† traiter (d√©faut: tous les pays configur√©s)
    """
    print("üöÄ D√©marrage de l'analyse des codes promo...")
    print(f"   üì¶ Taille des batches: {batch_size}")
    print("")
    
    # R√©cup√©rer le client et le spreadsheet du jour
    client = get_gspread_client()
    spreadsheet = find_todays_spreadsheet(client)
    
    if not spreadsheet:
        print("‚ùå Impossible de trouver le spreadsheet du jour!")
        return []
    
    # Liste des pays √† traiter
    target_countries = countries if countries else COUNTRY_SHEETS
    print(f"üìç Pays √† traiter: {', '.join(target_countries)}\n")
    
    all_results = []
    
    # Traiter chaque pays (sheet)
    for country in target_countries:
        print(f"\n{'='*60}")
        print(f"üåç TRAITEMENT DU PAYS: {country}")
        print(f"{'='*60}")
        
        try:
            worksheet = spreadsheet.worksheet(country)
        except gspread.WorksheetNotFound:
            print(f"   ‚ö†Ô∏è Sheet '{country}' non trouv√©e - skip")
            continue
        
        batch_num = 1
        country_results = []
        
        # Boucler sur les batches jusqu'√† ce qu'il n'y ait plus de codes
        while True:
            print(f"\nüì¶ BATCH #{batch_num} - {country}")
            
            # 1. R√©cup√©rer le prochain batch
            records = get_missing_codes(worksheet, batch_size=batch_size)
            
            if not records:
                if batch_num == 1:
                    print(f"‚úÖ {country} d√©j√† compl√®tement trait√© - skip")
                else:
                    print(f"‚úÖ Tous les codes de {country} ont √©t√© trait√©s!")
                break
            
            # 2. R√©√©crire les titres avec le LLM (dans la bonne langue)
            results = analyze_all_codes(records, country)
            
            # 3. Mettre √† jour le sheet imm√©diatement
            update_sheet_with_results(worksheet, results)
            
            # 4. Ajouter aux r√©sultats
            country_results.extend(results)
            all_results.extend(results)
            
            # 5. Afficher le r√©sum√© du batch
            print(f"\nüìä R√©sum√© du batch #{batch_num} ({country}):")
            print(f"   ‚úÖ {len(results)} codes analys√©s et mis √† jour")
            
            batch_num += 1
        
        # R√©sum√© pour ce pays
        if country_results:
            print(f"\n‚úÖ {country}: {len(country_results)} codes trait√©s au total")
    
    # Afficher le r√©sum√© global
    if all_results:
        print(f"\n{'='*60}")
        print(f"üìä R√âSUM√â GLOBAL - {len(all_results)} codes trait√©s")
        print(f"{'='*60}")
        print_summary(all_results)
        
        # Sauvegarder en JSON (backup)
        output_path = save_results_json(all_results)
        print(f"\n‚úÖ Analyse termin√©e!")
        print(f"üìÅ Backup JSON: {output_path}")
    
    return all_results


if __name__ == "__main__":
    import sys
    
    # Arguments: python code_analyzer.py [batch_size] [countries]
    # Exemple: python code_analyzer.py 100 UK,US,FR
    batch_size = int(sys.argv[1]) if len(sys.argv) > 1 else 100
    countries = sys.argv[2].split(",") if len(sys.argv) > 2 else None
    
    main(batch_size=batch_size, countries=countries)
